{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install langchain langchain-community python_dotenv\n",
    "# %pip install langchain-openai\n",
    "\n",
    "# %pip install pandas numpy\n",
    "# %pip install streamlit\n",
    "\n",
    "# %pip install \"unstructured[all-docs]<=0.16.10\"\n",
    "# %pip install langchain_postgres\n",
    "\n",
    "# %pip install redis>=4.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough,RunnableLambda\n",
    "\n",
    "from langchain_postgres.vectorstores import PGVector\n",
    "from database import COLLECTION_NAME, CONNECTION_STRING\n",
    "from langchain_community.storage import RedisStore\n",
    "from langchain.schema.document import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from base64 import b64decode\n",
    "import os, hashlib, shutil, uuid, json, time\n",
    "import torch, redis, streamlit as st\n",
    "import logging\n",
    "# Initialize Redis client\n",
    "client = redis.Redis(host=\"localhost\", port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = Path(\"data/hbspapers_48__1.pdf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition tables and text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_loading():\n",
    "\n",
    "    raw_pdf_elements = partition_pdf(\n",
    "        filename=FILE_PATH,\n",
    "      \n",
    "        infer_table_structure=True,\n",
    "        strategy = \"hi_res\",\n",
    "        \n",
    "        extract_image_block_types = [\"Image\"],\n",
    "        extract_image_block_to_payload  = True,\n",
    "\n",
    "        chunking_strategy=\"by_title\",     \n",
    "        mode='elements',\n",
    "        max_characters=10000,\n",
    "        new_after_n_chars=5000,\n",
    "        combine_text_under_n_chars=2000,\n",
    "        image_output_dir_path=\"data/\",\n",
    "    )\n",
    "    return raw_pdf_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_elements = data_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables[0].metadata.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [element.metadata.text_as_html for element in pdf_elements if 'Table' in str(type(element))]\n",
    "text = [element.text for element in pdf_elements if 'CompositeElement' in str(type(element))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# display(HTML(tables[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize extracted text and tables using LLM\n",
    "def summarize_text_and_tables(text, tables):\n",
    "    logging.info(\"Ready to summarize data with LLM\")\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing text and tables. \\\n",
    "    \n",
    "                    You are to give a concise summary of the table or text and do nothing else. \n",
    "                    Table or text chunk: {element} \"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "    model = ChatOpenAI(temperature=0.6, model=\"gpt-4o-mini\")\n",
    "    summarize_chain = {\"element\": RunnablePassthrough()}| prompt | model | StrOutputParser()\n",
    "    logging.info(f\"{model} done with summarization\")\n",
    "    return {\n",
    "        \"text\": summarize_chain.batch(text, {\"max_concurrency\": 5}),\n",
    "        \"table\": summarize_chain.batch(tables, {\"max_concurrency\": 5})\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary = summarize_text_and_tables(text, tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_retriever():\n",
    "\n",
    "    store = RedisStore(client=client)\n",
    "    id_key = \"doc_id\"\n",
    "    vectorstore = PGVector(\n",
    "            embeddings=OpenAIEmbeddings(),\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            connection=CONNECTION_STRING,\n",
    "            use_jsonb=True,\n",
    "            )\n",
    "    retrieval_loader = MultiVectorRetriever(vectorstore=vectorstore, docstore=store, id_key=\"doc_id\")\n",
    "    return retrieval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_retriever = initialize_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Summary to vectorstore & Raw data to RedisStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store text, tables, and their summaries in the retriever\n",
    "\n",
    "def store_docs_in_retriever(text, text_summary, table, table_summary, retriever):\n",
    "    \"\"\"Store text and table documents along with their summaries in the retriever.\"\"\"\n",
    "\n",
    "    def add_documents_to_retriever(documents, summaries, retriever, id_key = \"doc_id\"):\n",
    "        \"\"\"Helper function to add documents and their summaries to the retriever.\"\"\"\n",
    "        if not summaries:\n",
    "            return None, []\n",
    "\n",
    "        doc_ids = [str(uuid.uuid4()) for _ in documents]\n",
    "        summary_docs = [\n",
    "            Document(page_content=summary, metadata={id_key: doc_ids[i]})\n",
    "            for i, summary in enumerate(summaries)\n",
    "        ]\n",
    "\n",
    "        retriever.vectorstore.add_documents(summary_docs, ids=doc_ids)\n",
    "        retriever.docstore.mset(list(zip(doc_ids, documents)))     \n",
    "\n",
    "# Add text, table, and image summaries to the retriever\n",
    "    add_documents_to_retriever(text, text_summary, retriever)\n",
    "    add_documents_to_retriever(table, table_summary, retriever)\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever  = store_docs_in_retriever(text, text_summary, tables,  tables_summary, load_retriever)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the comparison of the composition of red meat and vegetarian protein sources\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse the retriever output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_retriver_output(data):\n",
    "    parsed_elements = []\n",
    "    for element in data:\n",
    "        # Decode bytes to string if necessary\n",
    "        if isinstance(element, bytes):\n",
    "            element = element.decode(\"utf-8\")\n",
    "        \n",
    "        parsed_elements.append(element)\n",
    "    \n",
    "    return parsed_elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat with the LLM using retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_llm():\n",
    "\n",
    "\n",
    "    prompt_text = \"\"\"\n",
    "                You are an AI Assistant tasked with understanding detailed\n",
    "                information from text and tables. You are to answer the question based on the \n",
    "                context provided to you. You must not go beyond the context given to you.\n",
    "                \n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "                \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "    model = ChatOpenAI(temperature=0.6, model=\"gpt-4o-mini\")\n",
    "\n",
    "    rag_chain = {\n",
    "       \"context\": retriever | RunnableLambda(parse_retriver_output), \"question\": RunnablePassthrough(),\n",
    "        } | RunnablePassthrough().assign(\n",
    "        response=(\n",
    "        prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    "        )\n",
    "        )\n",
    "\n",
    "    return rag_chain\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = chat_with_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"What is the nutrient composition of beef, veal, lamb and mutton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"What is the nutrient composition of organ meats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rag_chain.invoke(\"What is Meat?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
